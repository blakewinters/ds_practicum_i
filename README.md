# Practicum I: Prosper Loan Analysis

## Project Summary

Prosper is a Peer-to-Peer (P2P) lending platform that allows both individual and institutional investors to provide loans to other individuals. This marketplace is unique in its ability to circumvent traditional banks or money lending companies in providing needed funds to individuals. This has the benefit of giving individuals with low credit history or other traditionally negative financial characteristics the opportunity to receive a loan.
  
In the following analysis, I will be analyzing just over a million loans ranging from 2005 to present. The goal of the project is to predict which loans will provide the best investment opportunities from the perspective of defaults. 





The goal will be to provide a complete analysis for the use of investors as well as alternative views into the data so that needy loan recipients that may be overlooked by traditional credit metrics may be reevaluated and receive loans themselves. The primary data science task is prediction following EDA and determining the proper algorithm. 
	The data will be pulled from the Prosper Investor API. The company originates close to 3 million loans per year, so I expect the data set to be at least that large. I expect the data collection phase to be a significant portion of this project, as I will need to familiarize myself with the API features and then clean the data set. 
  
The entirety of this project will be performed using Python. I will start the analysis with a complete EDA. This will guide the direction of the bulk of the project itself. Following the EDA, I will perform a variety of machine learning techniques to determine which one is ideal. I plan to use regression for the prediction as that is well within my comfort level, but I would also like to utilize and test decision trees to see if I can improve performance. I will provide various visualizations to explain the results of the analysis and provide guidance for future analysis of loans. 

I expect to run into problems pulling the data, as I am not experienced using APIs to pull data. However, I have done this in Python several times, so I hope to use this experience to strengthen my abilities. There is significant documentation available for the API that I will be using to guide my steps. 


## Data

## EDA

## Models

## Conclusion

## References
https://docs.dask.org/en/latest/dataframe.html

https://www.analyticsvidhya.com/blog/2020/02/joins-in-pandas-master-the-different-types-of-joins-in-python/

https://stackoverflow.com/questions/8419564/difference-between-two-dates-in-python

https://datascience.stackexchange.com/questions/70298/labelencoding-selected-columns-in-a-dataframe-using-for-loop

https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html

https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html

https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd

https://stackabuse.com/implementing-pca-in-python-with-scikit-learn/

https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8

https://stackoverflow.com/questions/57085897/python-logistic-regression-max-iter-parameter-is-reducing-the-accuracy

https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/

https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9

https://stackabuse.com/decision-trees-in-python-with-scikit-learn/
